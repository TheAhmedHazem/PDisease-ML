{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "plt.style.use('seaborn-v0_8-poster')\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\\\IMPORTANT DATA\\\\AIU Computer Engineering\\\\CE Year 2\\\\Semester 2\\\\AIE121 Machine Learning\\\\Project\\\\parkinsons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The dataset used was imported from the following source: https://archive.ics.uci.edu/dataset/174/parkinsons***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Counting the number of features in the dataset.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking the data types of all the features to know which ones to omit and which ones to keep***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking for any missing values.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking for any duplicated data.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Moving the 'status' column to the end as it represents the dependent feature in this dataset.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.pop('status')\n",
    "df['status'] = df1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dropping the 'name' column because it isn't of any use***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('name', axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***There are 147 people diagnosed with Parkinson's and 48 who aren't.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for class imbalances \n",
    "- ***Majority Class***: 1 or people with Parkinson's \n",
    "- ***Minority Class***: 0 or people without Parkinson's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1 = 147 / 195\n",
    "class2 = 48 / 195\n",
    "print(\"Majority Class : \", class1)\n",
    "print(\"Minority class: \", class2)\n",
    "data = [class1, class2]\n",
    "keys = ['Class 1', 'Class 2']\n",
    "plt.pie(data, labels = keys, radius = 0.75, \n",
    "        autopct = '%1.2f%%', textprops = { 'fontsize' : 18})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Since the degree of imbalance is mild, i.e 20-40%, there isn't a need for downsampling or upweighting.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize = (16, 5))\n",
    "sns.boxplot(x = 'spread1', data = df, ax = ax[0], orient = 'v')\n",
    "sns.boxplot(x = 'spread2', data = df, ax = ax[1], orient = 'v')\n",
    "sns.boxplot(x = 'PPE', data = df, ax = ax[2], orient = 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Plotting the distribution of the minimum, average, and maximum vocal fundamental frequencies respectively and displaying lines to mark the mean (red line) and median (blue dashed line) for each frequency.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x = \"MDVP:Flo(Hz)\", kde = True)\n",
    "plt.axvline(x = df['MDVP:Flo(Hz)'].mean(),\n",
    "            color='red')\n",
    "plt.axvline(x = df['MDVP:Flo(Hz)'].median(),\n",
    "            color='blue',\n",
    "            ls='--', \n",
    "            lw=2.5)\n",
    "sns.displot(df, x = \"MDVP:Fo(Hz)\", kde = True)\n",
    "plt.axvline(x = df['MDVP:Fo(Hz)'].mean(),\n",
    "            color='red')\n",
    "plt.axvline(x = df['MDVP:Fo(Hz)'].median(),\n",
    "            color='blue',\n",
    "            ls='--', \n",
    "            lw=2.5)\n",
    "sns.displot(df, x = \"MDVP:Fhi(Hz)\", kde = True)\n",
    "plt.axvline(x = df['MDVP:Fhi(Hz)'].mean(),\n",
    "            color='red')\n",
    "plt.axvline(x = df['MDVP:Fhi(Hz)'].median(),\n",
    "             color='blue',\n",
    "             ls=\"--\",\n",
    "             lw=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The measures of the minimum, average, and maximum vocal fundamental frequencies are shown above*** \\\n",
    "\n",
    "**Observations**:\n",
    "- The distribution of the min vocal fundamental frequency is positively skewed with most values being in the 65Hz - 125Hz range.\n",
    "- The avg vocal fundamental frequency is quite similar to a normal distribution while most of its values range from ~110Hz - ~130Hz.\n",
    "- The max vocal frequency is almost normally distributed with some outliers on its right tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x = \"NHR\", kde = True)\n",
    "sns.displot(df, x = \"HNR\", kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x = \"MDVP:Shimmer(dB)\", kde = True) \n",
    "sns.displot(df, x = \"MDVP:Shimmer\", kde = True) \n",
    "sns.displot(df, x = \"Shimmer:APQ3\", kde = True) \n",
    "sns.displot(df, x = \"Shimmer:APQ5\", kde = True) \n",
    "sns.displot(df, x = \"MDVP:APQ\", kde = True) \n",
    "sns.displot(df, x = \"Shimmer:DDA\", kde = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df, x = 'spread1', hue = df['status'], fill = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(16,8))\n",
    "sns.boxplot(x = 'status', y = 'NHR', data = df, ax = ax[0])\n",
    "sns.boxplot(x = 'status', y = 'HNR', data = df, ax = ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"MDVP:Jitter(%)\", \"MDVP:Jitter(%)\", \"MDVP:RAP\", \"MDVP:PPQ\", \"Jitter:DDP\"]\n",
    "fig, axs = plt.subplots(ncols = 5, figsize = (16, 8))\n",
    "fig.tight_layout()\n",
    "for i in range(0, len(cols)):\n",
    "    sns.boxplot(x = 'status', y = cols[i], data = df, \n",
    "                ax = axs[i], palette = \"flare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize = (16,8))\n",
    "sns.boxplot(x = 'status', y = 'MDVP:Flo(Hz)', data = df, palette = \"Set1\", ax = ax[0])\n",
    "sns.boxplot(x = 'status', y = 'MDVP:Fo(Hz)', data = df, palette = \"Set1\", ax = ax[1])\n",
    "sns.boxplot(x = 'status', y = 'MDVP:Fhi(Hz)', data = df, palette = \"Set1\", ax = ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "sns.set_context(\"notebook\", font_scale = 1.0, rc = {\"lines.linewidth\": 3.5})\n",
    "plt.figure(figsize=(18, 7))\n",
    "# create a mask so we only see the correlation values once\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask, 1)] = True\n",
    "a = sns.heatmap(corr, mask = mask, annot = True, fmt = '.2f')\n",
    "rotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "roty = a.set_yticklabels(a.get_yticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"status\",axis=1)\n",
    "Y = df[\"status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = train_test_split(X, Y,train_size=0.7, test_size=0.3, random_state=40)\n",
    "print(len(X_train)),print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "k_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = k_model.predict(X_test)\n",
    "KNNScore = accuracy_score(y_test,y_pred)\n",
    "KNNScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_misclassified = (y_test != y_pred).sum()\n",
    "print('Misclassified samples in KNN: {}'.format(count_misclassified))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "df = xgb.DMatrix(data = X, label = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective' : 'binary:logistic',\n",
    "    'max_depth' : 3,\n",
    "    'alpha' : 4,\n",
    "    'learning_rate' : 0.1,\n",
    "    'n_estimators' : 500\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred2 = xgb_model.predict(X_test)\n",
    "XGBScore = accuracy_score(y_test, y_pred2)\n",
    "XGBScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_frst = RandomForestClassifier(n_estimators = 50)\n",
    "rand_frst = rand_frst.fit(X_train, y_train)\n",
    "y_pred1 = rand_frst.predict(X_test)\n",
    "RForestScore = accuracy_score(y_test, y_pred1)\n",
    "RForestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_frst = RandomForestClassifier(n_estimators = 50)\n",
    "rand_frst = rand_frst.fit(X_train, y_train)\n",
    "y_pred1 = rand_frst.predict(X_test)\n",
    "RForestScore = accuracy_score(y_test, y_pred1)\n",
    "RForestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_misclassified = (y_test != y_pred1).sum()\n",
    "print('Misclassified samples in Random Forest: {}'.format(count_misclassified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(rand_frst.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
    "feature_imp\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmCl = SVC(kernel = 'linear', random_state = 100)\n",
    "svmCl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = svmCl.predict(X_test)\n",
    "SVMScore = accuracy_score(y_test, y_pred3)\n",
    "SVMScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance data\n",
    "models = ['KNN', 'XGBoost', 'Random Forest', 'SVM']\n",
    "accuracies = [0.9491525423728814, 0.9491525423728814, 0.9661016949152542, 0.9322033898305084]\n",
    "\n",
    "# Create bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(models, accuracies, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "\n",
    "# Customize the chart\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_ylim(0.9, 1.0)  # Set y-axis to start from 0.9 for better visibility of differences\n",
    "\n",
    "# Add value labels on the bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.4f}',\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "# Add a horizontal line at y=1 for reference\n",
    "ax.axhline(y=1, color='r', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
